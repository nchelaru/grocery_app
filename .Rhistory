#   html_attr("aria-label")  %>%
#   str_extract("(\\d+.\\d+)")
## No. reviews
# num_reviews <- var %>%
#   html_nodes('#resultsCol .slNoUnderline') %>%
#   html_text() %>%
#   str_extract("(\\w+).+")
listings <- rbind(listings, as.data.frame(cbind(title,
company,
location,
summary,
link)))
}
listings %>% distinct(title, summary, .keep_all = T)
library(httr)
library(jsonlite)
library(rvest)
library(tidyverse)
library(dplyr)
library(magrittr)
library(digest)
library(XML)
library(stringr)
library(zoo)
library(knitr)
listings <- data.frame(title=character(),
company=character(),
location=character(),
summary=character(),
link=character(),
stringsAsFactors=FALSE)
for (i in seq(0, 200, 10)){
url_ds <- paste0('https://ca.indeed.com/jobs?q=data+(python+or+R)&l=Ontario&start=',i)
var <- read_html(url_ds)
#job title
title <-  var %>%
html_nodes('#resultsCol .jobtitle') %>%
html_text() %>%
str_extract("(\\w+.+)+")
#company
company <- var %>%
html_nodes('#resultsCol .company') %>%
html_text() %>%
str_extract("(\\w+).+")
#location
location <- var %>%
html_nodes('#resultsCol .accessible-contrast-color-location') %>%
html_text() %>%
str_extract("(\\w+.)+,.[A-Z]{2}")
#summary
summary <- var %>%
html_nodes('#resultsCol .summary') %>%
html_text() %>%
str_extract(".+")
#link
link <- var %>%
html_nodes('#resultsCol .jobtitle .turnstileLink, #resultsCol a.jobtitle') %>%
html_attr('href')
link <- paste0("https://ca.indeed.com",link)
## Rating
# rating <- var %>%
#   html_nodes('#resultsCol .ratings') %>%
#   html_attr("aria-label")  %>%
#   str_extract("(\\d+.\\d+)")
## No. reviews
# num_reviews <- var %>%
#   html_nodes('#resultsCol .slNoUnderline') %>%
#   html_text() %>%
#   str_extract("(\\w+).+")
listings <- rbind(listings, as.data.frame(cbind(title,
company,
location,
summary,
link)))
}
for (i in (1:length(listings$link))){
description <- tryCatch(
html_text(html_node(read_html(as.character(listings$link[i])),'.jobsearch-JobComponent-description')),
error=function(e){NA}
)
if (is.null(description)){
desc <- NA
}
meta <- tryCatch(
html_text(html_node(read_html(as.character(listings$link[i])),'.jobsearch-JobMetadataFooter')),
error=function(e){NA}
)
if (is.null(description)){
meta <- NA
}
listings$meta[i] <- meta
listings$description[i] <- description
}
library(httr)
library(jsonlite)
library(rvest)
library(tidyverse)
library(dplyr)
library(magrittr)
library(digest)
library(XML)
library(stringr)
library(zoo)
library(knitr)
listings <- data.frame(title=character(),
company=character(),
location=character(),
summary=character(),
link=character(),
stringsAsFactors=FALSE)
for (i in seq(0, 200, 10)){
url_ds <- paste0('https://ca.indeed.com/jobs?q=data+(python+or+R)&l=Ontario&start=',i)
var <- read_html(url_ds)
#job title
title <-  var %>%
html_nodes('#resultsCol .jobtitle') %>%
html_text() %>%
str_extract("(\\w+.+)+")
#company
company <- var %>%
html_nodes('#resultsCol .company') %>%
html_text() %>%
str_extract("(\\w+).+")
#location
location <- var %>%
html_nodes('#resultsCol .accessible-contrast-color-location') %>%
html_text() %>%
str_extract("(\\w+.)+,.[A-Z]{2}")
#summary
summary <- var %>%
html_nodes('#resultsCol .summary') %>%
html_text() %>%
str_extract(".+")
#link
link <- var %>%
html_nodes('#resultsCol .jobtitle .turnstileLink, #resultsCol a.jobtitle') %>%
html_attr('href')
link <- paste0("https://ca.indeed.com",link)
## Rating
# rating <- var %>%
#   html_nodes('#resultsCol .ratings') %>%
#   html_attr("aria-label")  %>%
#   str_extract("(\\d+.\\d+)")
## No. reviews
# num_reviews <- var %>%
#   html_nodes('#resultsCol .slNoUnderline') %>%
#   html_text() %>%
#   str_extract("(\\w+).+")
listings <- rbind(listings, as.data.frame(cbind(title,
company,
location,
summary,
link)))
}
listings <- listings %>% distinct(title, company, summary, .keep_all = T)
for (i in (1:length(listings$link))){
description <- tryCatch(
html_text(html_node(read_html(as.character(listings$link[i])),'.jobsearch-JobComponent-description')),
error=function(e){NA}
)
if (is.null(description)){
desc <- NA
}
meta <- tryCatch(
html_text(html_node(read_html(as.character(listings$link[i])),'.jobsearch-JobMetadataFooter')),
error=function(e){NA}
)
if (is.null(description)){
meta <- NA
}
listings$meta[i] <- meta
listings$description[i] <- description
}
listings
listings <- listings %>%
separate(col = meta, sep='- ', into=c('v1', 'date', 'v3')) %>%
select (-c(v1, v3))
listings$posting_date <- listings$date
listings
listings$posting_date <- listings$date
listings$date <- listings$date %>%
gsub("Just posted", "0", .) %>%
gsub("Today", "0", .) %>%
gsub(".* hour.* ago", "1", .) %>%
gsub("day ago", "", .) %>%
gsub("days ago", "", .) %>%
gsub('\\+', '', .)
date_diff <- function (date) {
diff <- Sys.Date() - date
return(diff)
}
listings$post_date <- as.Date(sapply(as.numeric(listings$date), function(x) date_diff(x)))
llistings
listings
for (i in 1:nrow(listings)) {
row <- listings[i,]
company_name <- gsub(' ', '\\+', row$company)
location <-  gsub(', ', '\\+', row$location)
url <- sprintf('https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=%s+%s&inputtype=textquery&fields=geometry,formatted_address&key=AIzaSyBhcwSvkdZSnZb1hqk5QcchGpV1fIw4i-w', company_name, location)
res = GET(url)
res_text <- content(res, "text")
res_json <- fromJSON(res_text, flatten = TRUE)
if (res_json$status == 'ZERO_RESULTS') {
row$lat <- NA
row$lng <- NA
row$address <- NA
} else {
listings$lat[i] <- res_json$candidates[1, ]$geometry.location.lat
listings$lng[i] <- res_json$candidates[1, ]$geometry.location.lng
listings$address[i] <- res_json$candidates[1, ]$formatted_address
}
}
listings
for (i in 1:nrow(listings)) {
row <- listings[i,]
company_name <- gsub(' ', '\\+', row$company)
location <-  gsub(' ', '\\+', row$location)
url <- sprintf('https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=%s+%s&inputtype=textquery&fields=geometry,formatted_address&key=AIzaSyBhcwSvkdZSnZb1hqk5QcchGpV1fIw4i-w', company_name, location)
res = GET(url)
res_text <- content(res, "text")
res_json <- fromJSON(res_text, flatten = TRUE)
if (res_json$status == 'ZERO_RESULTS') {
row$lat <- NA
row$lng <- NA
row$address <- NA
} else {
listings$lat[i] <- res_json$candidates[1, ]$geometry.location.lat
listings$lng[i] <- res_json$candidates[1, ]$geometry.location.lng
listings$address[i] <- res_json$candidates[1, ]$formatted_address
}
}
listings
listings %>% arrange(address)
listings %>% select(title, company, address) %>% arrange(address)
listings %>% select(title, address) %>% arrange(address)
listings %>% select(title, company, address) %>% arrange(address)
shiny::runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
listings %>% select(title, company, address, location) %>% arrange(address)
listings %>% select(title, company, address, location) %>% arrange(address)
library(httr)
library(jsonlite)
res = GET('https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=Winder+Tech+Mississauga,+ON&inputtype=textquery&fields=geometry,formatted_address&key=AIzaSyBhcwSvkdZSnZb1hqk5QcchGpV1fIw4i-w')
res_text <- content(res, "text")
res_json <- fromJSON(res_text, flatten = TRUE)
#res_json$candidates$geometry.location.lat
#res_json$candidates$geometry.location.lng
res_json$candidates
library(httr)
library(jsonlite)
res = GET('https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=Winder+Tech+Mississauga+ON&inputtype=textquery&fields=geometry,formatted_address&key=AIzaSyBhcwSvkdZSnZb1hqk5QcchGpV1fIw4i-w')
res_text <- content(res, "text")
res_json <- fromJSON(res_text, flatten = TRUE)
#res_json$candidates$geometry.location.lat
#res_json$candidates$geometry.location.lng
res_json$candidates
for (i in 1:nrow(listings)) {
row <- listings[i,]
company_name <- gsub(' ', '\\+', row$company)
location <-  gsub(' ', '\\+', row$location)
url <- sprintf('https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=%s+%s&inputtype=textquery&fields=geometry,formatted_address&key=AIzaSyBhcwSvkdZSnZb1hqk5QcchGpV1fIw4i-w', company_name, location)
res = GET(url)
res_text <- content(res, "text")
res_json <- fromJSON(res_text, flatten = TRUE)
if (!res_json$status == 'ZERO_RESULTS') {
listings$lat[i] <- res_json$candidates[1, ]$geometry.location.lat
listings$lng[i] <- res_json$candidates[1, ]$geometry.location.lng
listings$address[i] <- res_json$candidates[1, ]$formatted_address
} else {
url <- sprintf('https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=%s&inputtype=textquery&fields=geometry,formatted_address&key=AIzaSyBhcwSvkdZSnZb1hqk5QcchGpV1fIw4i-w', location)
res = GET(url)
res_text <- content(res, "text")
res_json <- fromJSON(res_text, flatten = TRUE)
listings$lat[i] <- res_json$candidates[1, ]$geometry.location.lat
listings$lng[i] <- res_json$candidates[1, ]$geometry.location.lng
listings$address[i] <- res_json$candidates[1, ]$formatted_address
}
}
listings %>% select(title, company, address, location) %>% arrange(address)
summary_df <- listings %>% group_by(address) %>% tally()
plot_geo(listings, locationmode = 'USA-states', sizes = c(1, 250)) %>%
add_markers(x = ~lng, y = ~lat, size=n, hoverinfo = "text")
summary_df <- listings %>% group_by(address) %>% tally()
plot_geo(listings, locationmode = 'USA-states', sizes = c(1, 250)) %>%
add_markers(x = ~lng, y = ~lat, size=~n, hoverinfo = "text")
summary_df <- listings %>% group_by(address) %>% tally()
summary(df)
summary_df <- listings %>% group_by(address) %>% tally()
summary_df
summary_df <- listings %>% select(lat, lng, address) %>% group_by(address) %>% tally()
summary_df
listings$count <- listings  %>% group_by(address) %>% tally()
runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
install.packages("googleway")
runApp('Documents/GitHub/job_search_app')
locations_df <- listings %>% distinct(company, location)
locations_df
locations_df <- listings %>% distinct(company, location)
locations_df
for (i in 1:nrow(locations_df)) {
row <- listings[i,]
company_name <- gsub(' ', '\\+', row$company)
location <-  gsub(' ', '\\+', row$location)
url <- sprintf('https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=%s+%s&inputtype=textquery&fields=geometry,formatted_address&key=AIzaSyBhcwSvkdZSnZb1hqk5QcchGpV1fIw4i-w', company_name, location)
res = GET(url)
res_text <- content(res, "text")
res_json <- fromJSON(res_text, flatten = TRUE)
if (!res_json$status == 'ZERO_RESULTS') {
locations_df$lat[i] <- res_json$candidates[1, ]$geometry.location.lat
locations_df$lng[i] <- res_json$candidates[1, ]$geometry.location.lng
locations_df$address[i] <- res_json$candidates[1, ]$formatted_address
} else {
url <- sprintf('https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=%s&inputtype=textquery&fields=geometry,formatted_address&key=AIzaSyBhcwSvkdZSnZb1hqk5QcchGpV1fIw4i-w', location)
res = GET(url)
res_text <- content(res, "text")
res_json <- fromJSON(res_text, flatten = TRUE)
locations_df$lat[i] <- res_json$candidates[1, ]$geometry.location.lat
locations_df$lng[i] <- res_json$candidates[1, ]$geometry.location.lng
locations_df$address[i] <- res_json$candidates[1, ]$formatted_address
}
}
locations_df
listings$count <- listings %>% select(lat, lng, address) %>% group_by(address) %>% tally()
listings$count <- listings %>% group_by(address) %>% tally()
summary_df <- listings %>% group_by(address) %>% tally()
summary_df
summary_df <- listings %>% select(address, company, location)  %>% group_by(address) %>% tally()
summary_df
summary_df <- listings %>% select(company, location)  %>% group_by(company) %>% tally()
summary_df
summary_df <- listings %>% select(company, location)
summary_df %>% group_by(company) %>% tally()
summary_df <- listings %>% select(company, location)
summary_df$count <- summary_df %>% group_by(company) %>% tally()
summary_df <- listings %>% select(company, location)   %>% group_by(company, location) %>% tally()
listings[is.na(listings)] <- 0
summary_df <- listings %>% select(company, location)   %>% group_by(company, location) %>% tally()
listings[is.na(listings)] <- " "
listings[is.na(listings$location)] <- " "
summary_df <- head(listings, 10) %>% select(company, location)   %>% group_by(company, location) %>% tally()
summary_df <- head(listings, 10) %>% select(company, location)   %>% group_by(company, location) %>% tally()
summary_df
listings %>% select(title, company, address, location) %>% arrange(address) %>% as.character(location)
summary_df <- head(listings, 30) %>% select(company, location)   %>% group_by(company, location) %>% tally()
summary_df
summary_df <- listings %>% drop_na() %>% select(company, location) %>% group_by(company, location) %>% tally()
summary_df
summary_df <- listings %>% drop_na() %>% select(company, location) %>% group_by(company, location) %>% tally()
write.csv(summary_df, "/Users/nancy/Desktop/summary_df.csv")
summary_df <- listings %>% drop_na() %>% select(company, location, lat, lng) %>% group_by(company, location,  lat, lng) %>% tally()
summary_df
write.csv(summary_df, "/Users/nancy/Desktop/summary_df.csv")
summary_df <- listings %>% drop_na() %>% select(company, location, address, lat, lng) %>% group_by(company, location, address, lat, lng) %>% tally()
summary_df
write.csv(summary_df, "/Users/nancy/Desktop/summary_df.csv")
runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
runApp('Documents/GitHub/job_search_app')
summary_df <- read.csv("~/Desktop/summary_df.csv")
View(summary_df)
View(summary_df)
runApp('Documents/GitHub/job_search_app')
install.packages(c("bayestestR", "callr", "curl", "devtools", "digest", "DT", "ellipsis", "feather", "ggstatsplot", "htmlTable", "knitr", "metaBMA", "mgcv", "pairwiseComparisons", "pkgconfig", "raster", "recipes", "rstantools", "sf", "shinyAce", "sjmisc", "tidyquant", "tinytex", "TTR"))
library(reticulate)
library(reticulate)
pwd
getwd()
library(reticulate)
library(reticulate)
library(reticulate)
blogdown:::serve_site()
shiny::runApp('Downloads/a28e32f26fee48cdae0d4f515dae8d19')
install.packages("bs4Dash")
runApp('Downloads/a28e32f26fee48cdae0d4f515dae8d19')
runApp('Downloads/a28e32f26fee48cdae0d4f515dae8d19')
shiny::runApp('Downloads/a28e32f26fee48cdae0d4f515dae8d19')
shiny::runApp('Downloads/a28e32f26fee48cdae0d4f515dae8d19')
runApp('Downloads/a28e32f26fee48cdae0d4f515dae8d19')
shiny::runApp('Documents/GitHub/grocery_app')
runApp('Documents/GitHub/grocery_app')
unique_stores <- function(search_term) {
res_json <- get_flyer(search_term)
filtered_data <- parse_flyer(res_json)
stores <- unique(filtered_data$merchant_name)
return(stores)
}
unique_stores("apples")
x = unique_stores("apples")
class(x)
list(x)
type(list(x))
class(list(x))
shiny::runApp('Documents/GitHub/grocery_app')
runApp()
runApp('Documents/GitHub/grocery_app')
x <- c("one", "two", "three")
class(x)
unique_stores <- function(search_term) {
nearby <- c('Loblaws', 'Metro', 'Sobeys', "Fortinos'", 'Walmart', 'T&T',
'Btrust', 'LCBO', 'Independent City Market', "Whole Foods")
res_json <- get_flyer(search_term)
filtered_data <- parse_flyer(res_json)
stores <- unique(filtered_data$merchant_name)
store_list <- list()
k <- 1
for (i in stores) {
if (i %in% nearby) {
store_list[[k]] <- i
k <- k+1
}
}
return(store_list)
}
unique_stores('apples')
runApp('Documents/GitHub/grocery_app')
runApp()
runApp('Documents/GitHub/grocery_app')
runApp('Documents/GitHub/grocery_app')
rlang::last_error()
runApp()
runApp('Documents/GitHub/grocery_app')
runApp('Documents/GitHub/grocery_app')
shiny::runApp('Documents/GitHub/grocery_app')
runApp('Documents/GitHub/grocery_app')
runApp(shinyApp(ui, server))
library(shiny); source('Documents/GitHub/grocery_app/scratch_file.R')
runApp('Documents/GitHub/grocery_app')
runApp('Documents/GitHub/grocery_app')
runApp('Documents/GitHub/grocery_app')
unique_stores('yogurt')
unique_stores('beef')
unique_stores <- function(search_term) {
res_json <- get_flyer(search_term)
filtered_data <- parse_flyer(res_json)
stores <- unique(filtered_data$merchant_name)
print(stores)
nearby <- c('Loblaws', 'Metro', 'Sobeys', "Fortinos'", 'Walmart', 'T&T',
'Btrust', 'LCBO', 'Independent City Market', "Whole Foods")
store_list <- list()
k <- 1
for (i in stores) {
if (i %in% nearby) {
store_list[[k]] <- i
k <- k+1
}
}
return(as.character(store_list))
}
unique_stores <- function(search_term) {
res_json <- get_flyer(search_term)
filtered_data <- parse_flyer(res_json)
stores <- unique(filtered_data$merchant_name)
print(stores)
nearby <- c('Loblaws', 'Metro', 'Sobeys', "Fortinos'", 'Walmart', 'T&T',
'Btrust', 'LCBO', 'Independent City Market', "Whole Foods")
store_list <- list()
k <- 1
for (i in stores) {
if (i %in% nearby) {
store_list[[k]] <- i
k <- k+1
}
}
return(as.character(store_list))
}
unique_stores('beef')
shiny::runApp('Documents/GitHub/grocery_app')
runApp('Documents/GitHub/grocery_app')
shiny::runApp('Documents/GitHub/grocery_app')
runApp('Documents/GitHub/grocery_app')
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
